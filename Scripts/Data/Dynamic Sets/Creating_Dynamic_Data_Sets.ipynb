{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b45e4e3e",
   "metadata": {},
   "source": [
    "# Notebook for Creating Dynamic Data Sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "768c77a1",
   "metadata": {},
   "source": [
    "### Read Edges and Busses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8371c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read Files\n",
    "busses = pd.read_excel('Busses_Timeseries_Table.xlsx')\n",
    "edges = pd.read_excel('Edges_Timeseries_Table.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c76d8d3c",
   "metadata": {},
   "source": [
    "### Node Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01b2f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Use busses and edges table\n",
    "def split_node(busses, edges, splitAt):\n",
    "    # Update Values Node one\n",
    "    busses.loc[busses['bus_id'] == splitAt, 'mw_norm'] = busses.mw_norm / 2\n",
    "    busses.loc[busses['bus_id'] == splitAt, 'min_ecomin'] = busses.min_ecomin / 2\n",
    "    busses.loc[busses['bus_id'] == splitAt, 'max_ecomax'] = busses.max_ecomax / 2\n",
    "    # h & c stays same (Needs to be solved for again)\n",
    "    \n",
    "    # Add Timeseries for New Node\n",
    "    busAtTimeseries = busses[busses['bus_id'] == splitAt]\n",
    "    newNode = busses[\"bus_id\"].max() + 1\n",
    "    busAtTimeseries.loc[:, 'bus_id'] = newNode\n",
    "    busses = pd.concat([busses, busAtTimeseries])\n",
    "    busses = busses.sort_values(by=['datetime_beginning_utc', 'bus_id'], ascending=True)\n",
    "    \n",
    "    #Create Edge, sample x and limit\n",
    "    xAverage = edges[edges['X'] != 0]['X'].mean()\n",
    "    limAverage = edges[edges['Lim MVA A'] != 0]['Lim MVA A'].mean()\n",
    "    xVal = xAverage * (1+ random.randint(-1, 1)/100)\n",
    "    limVal = limAverage * (1+ random.randint(-1, 2)/100)\n",
    "    edge1 = pd.DataFrame({'From Number':[splitAt], 'To Number':[newNode], 'X':[xVal], 'Lim MVA A': [limVal]})\n",
    "    timestamps = edges['datetime_beginning_utc'].unique()\n",
    "\n",
    "    # Cross Join to turn grid into timeseries data (same grid)\n",
    "    timeDF = pd.DataFrame(timestamps, columns=['datetime_beginning_utc'])\n",
    "    edgeTimeseries = pd.merge(timeDF[['datetime_beginning_utc']], edge1, how='cross')\n",
    "    edges = pd.concat([edges, edgeTimeseries])\n",
    "    edges = edges.sort_values(by=['datetime_beginning_utc', 'From Number'], ascending=True)\n",
    "    \n",
    "    # Add one year\n",
    "    busses['datetime_beginning_utc'] += pd.DateOffset(years=1)\n",
    "    edges['datetime_beginning_utc'] += pd.DateOffset(years=1)\n",
    "    \n",
    "    busses.reset_index(inplace = True, drop = True)\n",
    "    edges.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    return (busses, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a38ca4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nadin\\AppData\\Local\\Temp\\ipykernel_20448\\2854311747.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  busAtTimeseries.loc[:, 'bus_id'] = newNode\n"
     ]
    }
   ],
   "source": [
    "# Perform Split\n",
    "nodeIndex = 0\n",
    "bussesSplit, edgesSplit = split_node(busses, edges, nodeIndex)\n",
    "bussesSplit.reset_index(inplace = True, drop = True) # Adjust index\n",
    "edgesSplit.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d52d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bussesSplit.to_csv(\"Busses_Timeseries_Table_Set2023.csv\")\n",
    "edgesSplit.to_csv(\"Edges_Timeseries_Table_Set2023.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dcdc740",
   "metadata": {},
   "source": [
    "### Node Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6edfb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short version with group by\n",
    "def concat_node(busses, edges, concatTo):\n",
    "    delNode = busses[\"bus_id\"].max()\n",
    "    \n",
    "    #Nodes - make node id identical and then aggregate for identical id and time\n",
    "    busses.loc[busses['bus_id'] == delNode, 'bus_id'] = concatTo    \n",
    "    wm = lambda x: np.average(x, weights=busses.loc[x.index, \"mw_norm\"])\n",
    "    agg_functions = {'load_area': 'first', 'mw_norm': 'sum', 'solTheta': 'sum', 'min_ecomin': 'min', 'max_ecomax': 'sum', 'inter_start_cost': wm, 'incremental_price': wm, 'solGenerate': 'sum', 'solOn': 'max'}\n",
    "    busses = busses.groupby(['datetime_beginning_utc','bus_id']).aggregate(agg_functions).reset_index()\n",
    "    \n",
    "    # Edges - delete connecting edge, put edges to delte node to concat node and aggregate edges connecting same nodes\n",
    "    edges = edges.loc[~ (((edges['From Number'] == delNode) & (edges['To Number'] == concatTo)) | ((edges['From Number'] == concatTo) & (edges['To Number'] == delNode)))]\n",
    "    edges.loc[edges['From Number'] == delNode, 'From Number'] = concatTo\n",
    "    edges.loc[edges['To Number'] == delNode, 'To Number'] = concatTo \n",
    "    #Aggregate edges\n",
    "    agg_functions = {'X': 'mean', 'Lim MVA A': 'sum'}\n",
    "    edges = edges.groupby(['datetime_beginning_utc','To Number', 'From Number']).aggregate(agg_functions).reset_index()\n",
    "    \n",
    "    # Substract one year\n",
    "    busses['datetime_beginning_utc'] -= pd.DateOffset(years=1)\n",
    "    edges['datetime_beginning_utc'] -= pd.DateOffset(years=1)\n",
    "    return busses, edges\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f56ddfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeIndex = busses['bus_id'].max()\n",
    "bussesConcat, edgesConcat = concat_node(bussesConcat, edgesConcat, nodeIndex)\n",
    "edgesConcat = edgesConcat.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6e3296f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bussesConcat.to_csv(\"Busses_Timeseries_Table_Set2020.csv\")\n",
    "edgesConcat.to_csv(\"Edges_Timeseries_Table_Set2020.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
